{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the Make3D dataset\n",
    "http://make3d.cs.cornell.edu/data.html#make3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from Make3D import train_pairs, test_pairs\n",
    "\n",
    "#from NYU import nyu_data\n",
    "#train_pairs, test_pairs = nyu_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, axis = plt.subplots(5, 2, figsize=(10,20))\n",
    "plt.tight_layout()\n",
    "for (rgb, d), (ax1, ax2) in zip(train_pairs[:10], axis):\n",
    "    ax1.axis('off'), ax2.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(sp.misc.imresize(d, rgb.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take the paper's convolutional network approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify dataset first\n",
    "- Convert to grayscale\n",
    "- Scale targets down so the convolutional network can use striding and so we do not need padding\n",
    "- Normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, train_targets = zip(*train_pairs)\n",
    "test_data, test_targets = zip(*test_pairs)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "train_data = [sp.misc.imresize(rgb2gray(img), (304, 228))/255 for img in train_data]\n",
    "train_targets = [sp.misc.imresize(img, (74, 55))/255 for img in train_targets]\n",
    "test_data = [sp.misc.imresize(rgb2gray(img), (304, 228))/255 for img in test_data]\n",
    "test_targets = [sp.misc.imresize(img, (74, 55))/255 for img in test_targets]\n",
    "\n",
    "\n",
    "train_x, train_t = np.asarray(train_data), np.asarray(train_targets)\n",
    "test_x, test_t = np.asarray(test_data), np.asarray(test_targets)\n",
    "\n",
    "print('train input/target shapes', train_data[0].shape, train_targets[0].shape)\n",
    "print('train input min/max/ptp', np.min(train_data), np.max(train_data), np.ptp(train_data))\n",
    "print('train target min/max/ptp', np.min(train_targets), np.max(train_targets), np.ptp(train_targets))\n",
    "\n",
    "tuples = zip(train_x[:10], train_t[:10])\n",
    "fig, axis = plt.subplots(5, 2, figsize=(10,20))\n",
    "plt.tight_layout(), plt.gray()\n",
    "for (rgb, d), (ax1, ax2) in zip(tuples, axis):\n",
    "    ax1.axis('off'), ax2.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(sp.misc.imresize(d, rgb.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "x = tf.placeholder(tf.float32, (None, 304, 228))\n",
    "t = tf.placeholder(tf.float32, (None, 74, 55))\n",
    "is_test = tf.placeholder_with_default(False, None)\n",
    "x_ = tf.reshape(x, (-1, 304, 228, 1))\n",
    "\n",
    "\n",
    "#coarse layer implementation\n",
    "coarse = tf.layers.conv2d(x_, filters=96, kernel_size=11, strides=4, activation=tf.nn.relu)\n",
    "coarse = tf.layers.max_pooling2d(coarse, pool_size=2, strides=2)\n",
    "coarse = tf.layers.conv2d(coarse, filters=256, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "coarse = tf.layers.max_pooling2d(coarse, pool_size=2, strides=2)\n",
    "coarse = tf.layers.conv2d(coarse, filters=384, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "coarse = tf.layers.conv2d(coarse, filters=384, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "coarse = tf.layers.conv2d(coarse, filters=256, kernel_size=3, activation=tf.nn.relu, strides=2)\n",
    "coarse = tf.reshape(coarse, (-1, 8*6*256))\n",
    "coarse = tf.layers.dense(coarse, units=4096, activation=tf.nn.relu)\n",
    "coarse = tf.layers.dropout(coarse, rate=.5, training=is_test)  #schaltet beim training neurons aus\n",
    "coarse = tf.layers.dense(coarse, units=(74*55))\n",
    "coarse = tf.reshape(coarse, (-1, 74, 55, 1))\n",
    "\n",
    "\n",
    "#fine layer implementation\n",
    "fine = tf.layers.conv2d(x_, filters=63, kernel_size=9, strides=2, activation=tf.nn.relu)\n",
    "fine = tf.layers.max_pooling2d(fine, pool_size=2, strides=2)\n",
    "fine = tf.concat([fine, coarse], 3)\n",
    "fine = tf.layers.conv2d(fine, filters=64, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "fine = tf.layers.conv2d(fine, filters=1, kernel_size=5, padding='same')\n",
    "\n",
    "y = tf.squeeze(fine, axis=3)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(t - y))\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Regularily evaluate the loss on the test data and compute test predictions when done with training.\n",
    "\n",
    "**10000 epochs is nothing one wants to run on the CPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100 + 1):\n",
    "        batch = np.random.permutation(32)\n",
    "        batch_x, batch_t = train_x[batch], train_t[batch]\n",
    "        sess.run(optimizer, {x: batch_x, t: batch_t})\n",
    "        if i % 1 == 0:\n",
    "            print(i, sess.run(loss, {x: test_x, t: test_t}))\n",
    "    test_p = sess.run(y, {x: test_x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "triples = zip(test_x[:10], test_t[:10], test_p[:10])\n",
    "_, axis = plt.subplots(5, 3, figsize=(10,20))\n",
    "plt.tight_layout(), plt.gray()\n",
    "for (rgb, d, p), (ax1, ax2, ax3) in zip(triples, axis):\n",
    "    ax1.axis('off'), ax2.axis('off'), ax3.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(sp.misc.imresize(d, rgb.shape))\n",
    "    ax3.imshow(sp.misc.imresize(p, rgb.shape))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
