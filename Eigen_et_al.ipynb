{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigen et al 2014\n",
    "\n",
    "Eigen, David, Christian Puhrsch, and Rob Fergus. \"Depth map prediction from a single image using a multi-scale deep network.\" Advances in neural information processing systems. 2014. [[Eigen2014](https://papers.nips.cc/paper/5539-depth-map-prediction-from-a-single-image-using-a-multi-scale-deep-network.pdf)]\n",
    "\n",
    "## Datasets: \n",
    "- [Make3D](http://make3d.cs.cornell.edu/data.html#make3d)\n",
    "- [NYU](http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'Make3D'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9e73d4427dbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make3D data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mMake3D\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# NYU data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from NYU import nyu_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'Make3D'"
     ]
    }
   ],
   "source": [
    "# Make3D data\n",
    "from Make3D import train_pairs, test_pairs\n",
    "\n",
    "# NYU data\n",
    "# from NYU import nyu_data\n",
    "# train_pairs, test_pairs = nyu_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, axis = plt.subplots(5, 2, figsize=(10,20))\n",
    "plt.tight_layout()\n",
    "for (rgb, d), (ax1, ax2) in zip(train_pairs[:10], axis):\n",
    "    ax1.axis('off'), ax2.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(imresize(d, rgb.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take the paper's convolutional network approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify dataset first\n",
    "- Convert to grayscale\n",
    "- Scale targets down so the convolutional network can use striding and so we do not need padding\n",
    "- Normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_targets = zip(*train_pairs)\n",
    "test_data, test_targets = zip(*test_pairs)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "# Reshape data/targets to what the paper uses in order to use the same network.\n",
    "train_data = [imresize(rgb2gray(img), (304, 228))/255 for img in train_data]\n",
    "train_targets = [imresize(img, (74, 55))/255 for img in train_targets]\n",
    "test_data = [imresize(rgb2gray(img), (304, 228))/255 for img in test_data]\n",
    "test_targets = [imresize(img, (74, 55))/255 for img in test_targets]\n",
    "\n",
    "train_x, train_t = np.asarray(train_data), np.asarray(train_targets)\n",
    "test_x, test_t = np.asarray(test_data), np.asarray(test_targets)\n",
    "\n",
    "print('train input/target shapes', train_data[0].shape, train_targets[0].shape)\n",
    "print('train input min/max/ptp', np.min(train_data), np.max(train_data), np.ptp(train_data))\n",
    "print('train target min/max/ptp', np.min(train_targets), np.max(train_targets), np.ptp(train_targets))\n",
    "\n",
    "tuples = zip(train_x[:10], train_t[:10])\n",
    "fig, axis = plt.subplots(5, 2, figsize=(10,20))\n",
    "plt.tight_layout(), plt.gray()\n",
    "for (rgb, d), (ax1, ax2) in zip(tuples, axis):\n",
    "    ax1.axis('off'), ax2.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(imresize(d, rgb.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_95/Relu:0\", shape=(?, 70, 51, 64), dtype=float32)\n",
      "Tensor(\"max_pooling2d_35/MaxPool:0\", shape=(?, 35, 25, 64), dtype=float32)\n",
      "Tensor(\"conv2d_96/Relu:0\", shape=(?, 31, 21, 128), dtype=float32)\n",
      "Tensor(\"max_pooling2d_36/MaxPool:0\", shape=(?, 15, 10, 128), dtype=float32)\n",
      "Tensor(\"conv2d_97/Relu:0\", shape=(?, 11, 6, 256), dtype=float32)\n",
      "Tensor(\"conv2d_98/Relu:0\", shape=(?, 7, 2, 512), dtype=float32)\n",
      "Tensor(\"conv2d_99/Relu:0\", shape=(?, 70, 51, 64), dtype=float32)\n",
      "Tensor(\"max_pooling2d_37/MaxPool:0\", shape=(?, 35, 25, 64), dtype=float32)\n",
      "Tensor(\"conv2d_100/Relu:0\", shape=(?, 31, 21, 128), dtype=float32)\n",
      "Tensor(\"max_pooling2d_38/MaxPool:0\", shape=(?, 15, 10, 128), dtype=float32)\n",
      "Tensor(\"conv2d_101/Relu:0\", shape=(?, 11, 6, 256), dtype=float32)\n",
      "Tensor(\"conv2d_102/Relu:0\", shape=(?, 7, 2, 512), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#loss = tf.reduce_mean(tf.square(t - y))  # TODO: Implement loss from paper\\n\\n#nr_pixel = 74*55*32.\\n#nr_missing = tf.reduce_sum(tf.cast(t==0, tf.float32))\\n\\n#nr_missing = tf.Print(nr_missing, [nr_missing])\\n\\nn = tf.count_nonzero(y)\\nd = y - tf.log(t)\\ndsq = tf.square(d)\\n\\nloss = tf.reduce_mean( (1/n) * tf.reduce_sum(dsq, name=\"sum1\") - (1/n**2) * (tf.reduce_sum(d))**2 )\\n\\noptimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 304, 228))\n",
    "t = tf.placeholder(tf.float32, (None, 74, 55))\n",
    "training = tf.placeholder_with_default(False, None)\n",
    "t = tf.reshape(t, (-1, 74, 55, 1)) \n",
    "x_ = tf.reshape(x, (-1, 304, 228, 1))  # conv2d expects a channel dimension\n",
    "\n",
    "def generator(x):\n",
    "    # coarse network implementation\n",
    "    coarse = tf.layers.conv2d(x, filters=96, kernel_size=11, strides=4, activation=tf.nn.relu)\n",
    "    coarse = tf.layers.max_pooling2d(coarse, pool_size=2, strides=2)\n",
    "    coarse = tf.layers.conv2d(coarse, filters=256, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "    coarse = tf.layers.max_pooling2d(coarse, pool_size=2, strides=2)\n",
    "    coarse = tf.layers.conv2d(coarse, filters=384, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "    coarse = tf.layers.conv2d(coarse, filters=384, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "    coarse = tf.layers.conv2d(coarse, filters=256, kernel_size=3, activation=tf.nn.relu, strides=2)\n",
    "    coarse = tf.reshape(coarse, (-1, 8*6*256))\n",
    "    coarse = tf.layers.dense(coarse, units=4096, activation=tf.nn.relu)\n",
    "    coarse = tf.layers.dropout(coarse, rate=.5, training=training)  # kill neurons in training\n",
    "    coarse = tf.layers.dense(coarse, units=(74*55))\n",
    "    coarse = tf.reshape(coarse, (-1, 74, 55, 1))\n",
    "\n",
    "    # fine network implementation\n",
    "    fine = tf.layers.conv2d(x_, filters=63, kernel_size=9, strides=2, activation=tf.nn.relu)\n",
    "    fine = tf.layers.max_pooling2d(fine, pool_size=2, strides=2)\n",
    "    fine = tf.concat([fine, coarse], 3)  # join with coarse output\n",
    "    fine = tf.layers.conv2d(fine, filters=64, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "    fine = tf.layers.conv2d(fine, filters=1, kernel_size=5, padding='same')\n",
    "\n",
    "    #y = tf.squeeze(fine, axis=3)  # remove channel dimension\n",
    "    return fine #y\n",
    "\n",
    "def discriminator(x):\n",
    "    # inputdimension is (None, 74, 55)\n",
    "    # from http://bamos.github.io/2016/08/09/deep-completion/\n",
    "    # other one possible but no kernel sizes from https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-1-Generative-Adversarial-Nets\n",
    "    layer = tf.layers.conv2d(x, filters=64, kernel_size=5, strides=1, activation=tf.nn.relu)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=2, strides=2)\n",
    "    layer = tf.layers.conv2d(layer, filters=128, kernel_size=5, strides=1, activation=tf.nn.relu)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=2, strides=2)\n",
    "    layer = tf.layers.conv2d(layer, filters=256, kernel_size=5, strides=1, activation=tf.nn.relu)\n",
    "    layer = tf.layers.conv2d(layer, filters=512, kernel_size=5, strides=1, activation=tf.nn.relu)\n",
    "    # start fully connected layers\n",
    "    layer = tf.reshape(layer, (-1, 7*2*512))\n",
    "    \n",
    "    layer = tf.layers.dense(layer, units=256, activation=tf.nn.relu)\n",
    "    layer = tf.layers.dropout(layer, rate=.5, training=training)  # kill neurons in training\n",
    "    layer = tf.layers.dense(layer, units=128, activation=tf.nn.relu)\n",
    "    layer = tf.layers.dense(layer, units=32, activation=tf.nn.relu)\n",
    "    layer = tf.layers.dense(layer, units=16, activation=tf.nn.relu)\n",
    "    layer = tf.layers.dense(layer, units=8, activation=tf.nn.relu)\n",
    "    D_logit = tf.layers.dense(layer, units=1, activation=None)\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "    return D_prob, D_logit\n",
    "    \n",
    "\n",
    "G_sample = generator(x_)\n",
    "D_real, D_logit_real = discriminator(t)\n",
    "D_fake, D_logit_fake = discriminator(G_sample)\n",
    "\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss)#, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss)\n",
    "\n",
    "    \n",
    "\"\"\"#loss = tf.reduce_mean(tf.square(t - y))  # TODO: Implement loss from paper\n",
    "\n",
    "#nr_pixel = 74*55*32.\n",
    "#nr_missing = tf.reduce_sum(tf.cast(t==0, tf.float32))\n",
    "\n",
    "#nr_missing = tf.Print(nr_missing, [nr_missing])\n",
    "\n",
    "n = tf.count_nonzero(y)\n",
    "d = y - tf.log(t)\n",
    "dsq = tf.square(d)\n",
    "\n",
    "loss = tf.reduce_mean( (1/n) * tf.reduce_sum(dsq, name=\"sum1\") - (1/n**2) * (tf.reduce_sum(d))**2 )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Regularily evaluate the loss on the test data and compute test predictions when done with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "\n",
    "def print_progress(iteration, total, prefix='', suffix='', length=50):\n",
    "    percent = '{0:.2f}'.format(100 * (iteration / float(total)))\n",
    "    filledLength = int(round(length * iteration / float(total)))\n",
    "    bar = '=' * filledLength + '-' * (length - filledLength)\n",
    "    stdout.write('\\r%s |%s| %s%s %s' % (prefix, bar, percent, '%', suffix))\n",
    "    if iteration == total:\n",
    "        stdout.write('\\n')\n",
    "    stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1, EPOCHS + 1):\n",
    "        batch = np.random.permutation(len(train_t))[:32]\n",
    "        batch_x, batch_t = train_x[batch], train_t[batch]\n",
    "        sess.run(G_solver, {x: batch_x, t: batch_t, training: True})\n",
    "        sess.run(D_solver, {x: batch_x, training: True})\n",
    "        if i % 100 == 0:\n",
    "            train_loss = sess.run(loss, {x: batch_x, t: batch_t})\n",
    "            print_progress(i, EPOCHS, suffix='Loss: {}'.format(train_loss))\n",
    "    test_p = sess.run(y, {x: test_x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "- loss function\n",
    "- automatic early stoppage (alle 10 epochs auf test set evaluieren -> achtung overfitting)\n",
    "- pretraining\n",
    "- local fine scale network\n",
    "- KITTI dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "triples = zip(test_x[:20], test_t[:20], test_p[:20])\n",
    "_, axis = plt.subplots(5, 3, figsize=(10,20))\n",
    "plt.tight_layout(), plt.gray()\n",
    "for (rgb, d, p), (ax1, ax2, ax3) in zip(triples, axis):\n",
    "    ax1.axis('off'), ax2.axis('off'), ax3.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(imresize(d, rgb.shape))\n",
    "    ax3.imshow(imresize(p, rgb.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
